{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqFdbY0Gfp_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "6f8ce7f2-4031-41ab-bc80-6f42ae0805de"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_b-UDtEf3Vl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aYRJ9RVgVeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D167Rinwf8Eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = os.getcwd() + '/1'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojr503bEgISd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# file_ = open(file_path , 'r' , encoding='iso-8859-1')\n",
        "# \n",
        "# data = file_.readlines()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMKHQFOWhW9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9cc2615f-f3bc-4450-aa58-da94007b2f2a"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply , Embedding\n",
        "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model, Model\n",
        "import keras.backend as K\n",
        "\n",
        "# from faker import Faker\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "# from babel.dates import format_date\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkgTuXD1hekh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a66c25c-39a2-48aa-ec15-3f635e7c9dc2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "print(tf.__version__)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import io\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "import urllib3\n",
        "import shutil\n",
        "import zipfile\n",
        "import itertools\n",
        "from string import digits"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG-HsUH5WzvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMBRfYhUsN_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    \n",
        "    num_digits= str.maketrans('','', digits)\n",
        "    \n",
        "    sentence= sentence.lower()\n",
        "    sentence= re.sub(\" +\", \" \", sentence)\n",
        "    sentence= re.sub(\"'\", '', sentence)\n",
        "    sentence= sentence.translate(num_digits)\n",
        "    sentence= re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
        "    sentence = sentence.rstrip().strip()\n",
        "    sentence = \"<start> \" + sentence + \" <end>\"\n",
        "    \n",
        "    return sentence\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om3oBZUKsQjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "text = []\n",
        "count = 0\n",
        "\n",
        "\n",
        "with open(file_path ,'r' , encoding='iso-8859-1') as txtfile:\n",
        "  for line in txtfile.readlines():\n",
        "    if count == 20000:\n",
        "      break\n",
        "\n",
        "    text.append(preprocess_sentence(line.split('+++$+++')[-1]))\n",
        "    count +=1\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpOoKlJNsRnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "10dda5a2-e865-4298-c874-302825b2be57"
      },
      "source": [
        "len(text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJDNh--DsiZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b5453d7-cde7-4896-8f8d-bdcf5ee4f63c"
      },
      "source": [
        "text[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> they do not ! <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdm9QZtpskOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "max_len = 20\n",
        "trunc_token = 'post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=oov_tok , filters = \"\")\n",
        "tokenizer.fit_on_texts(text)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(text)\n",
        "padded = pad_sequences(sequences,maxlen=max_len, truncating=trunc_token,padding = 'post')\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRVZfm8yslh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8dd6336e-5aea-4d76-da46-1a42f4539edf"
      },
      "source": [
        "len(word_index)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13051"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omxIN5wrsm44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dfd9bde2-a869-4f6e-959d-53c15461dc43"
      },
      "source": [
        "padded[10008]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   3,   95,    6,   43,   11, 2168,   91,  114,    7,    4,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LChEIxE0soIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_word = {}\n",
        "for word , index in word_index.items():\n",
        "    index_word[index] = word\n",
        "    \n",
        "    "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXE2F1s8sqA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_word_embeddings(file_path):\n",
        "    \n",
        "    with open(file_path , 'r') as f:\n",
        "        wordToEmbedding = {}\n",
        "        wordToIndex = {}\n",
        "        indexToWord = {}\n",
        "        \n",
        "        for line in f:\n",
        "            data = line.strip().split()\n",
        "            token = data[0]\n",
        "            wordToEmbedding[token] = np.array(data[1:] ,dtype = np.float64)\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        tokens = sorted(wordToEmbedding.keys())\n",
        "        for idx , token in enumerate(tokens):\n",
        "            idx = idx + 1 #for zero masking\n",
        "            wordToIndex[token] = idx\n",
        "            indexToWord[idx] = token\n",
        "\n",
        "    return wordToEmbedding , wordToIndex , indexToWord\n",
        "            \n",
        "            "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPzMBhNessD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordToEmbedding , wordToIndex , indexToWord = create_word_embeddings(os.getcwd()+ '/glove.6B.200d.txt')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLI80EOzstoP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "67adf348-3b2a-43d1-a370-5268d7247a83"
      },
      "source": [
        "len(wordToIndex)    "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QHyzV1Esxzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_pretrained_embedding_layer(wordToEmbedding , wordToIndex , indexToWord):\n",
        "    \n",
        "    vocablen = len(word_index)+1 #for zero masking\n",
        "    embedding_dimensions = 200\n",
        "    \n",
        "    embeddingMatrix = np.zeros((vocablen , embedding_dimensions))\n",
        "    count = 0\n",
        "    for word , index in word_index.items():\n",
        "        if word not in wordToEmbedding.keys():\n",
        "            embeddingMatrix[index ,:] = np.random.uniform(low = -1 , high =1 ,size = (1,200))\n",
        "            count +=1\n",
        "        else :\n",
        "            \n",
        "            embeddingMatrix[index , :] = wordToEmbedding[word]\n",
        "        \n",
        "    embeddingLayer = Embedding(vocablen , embedding_dimensions , weights = [embeddingMatrix] , trainable = False)\n",
        "    print(embeddingMatrix.shape)\n",
        "    print(count)\n",
        "    \n",
        "    return embeddingMatrix"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHqtKeezszIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "49eed949-d1ef-4a39-a4ae-bedd336ab21c"
      },
      "source": [
        "len(word_index)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13051"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPd0InA-s0Xc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0bf2f79c-d707-4279-f350-9bd3295c4e13"
      },
      "source": [
        "embeddingMatrix = create_pretrained_embedding_layer(wordToEmbedding , wordToIndex , indexToWord)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13052, 200)\n",
            "1601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnhdl3k7s2T5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "10f6cd0e-906f-4daf-e07d-9ab48a58fc01"
      },
      "source": [
        "embeddingMatrix"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.09444563,  0.67830645, -0.23497883, ..., -0.33542104,\n",
              "        -0.91926708, -0.63332775],\n",
              "       [ 0.12289   ,  0.58037   , -0.069635  , ..., -0.039174  ,\n",
              "        -0.16236   , -0.096652  ],\n",
              "       ...,\n",
              "       [-0.25924   , -0.81193   ,  0.45847   , ...,  0.045301  ,\n",
              "         0.01518   , -0.36259   ],\n",
              "       [ 0.53246   ,  0.84359   ,  0.13337   , ...,  0.11501   ,\n",
              "        -0.33268   , -0.55189   ],\n",
              "       [-0.018711  ,  0.39573   ,  0.84356   , ...,  0.31973   ,\n",
              "        -0.28322   , -0.12453   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xaqerkfs3yB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset(padded):\n",
        "    index = 0\n",
        "    context = np.zeros((500,max_len))\n",
        "    response = np.zeros((500,max_len))\n",
        "    for idx in range(2000,3000,2):\n",
        "        context[index,:] = padded[idx]\n",
        "        response[index,:] = padded[idx+1]\n",
        "        index +=1\n",
        "    return context , response"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6jI7O0qs491",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context , response = get_dataset(padded)\n",
        "\n",
        "response1 = response[:,:-1]\n",
        "response2 = response[:,1:]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFwYCf3rs6Ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response2 = list(response2.swapaxes(0,1))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phqb0GtOs7Ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Layer\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply , Embedding , Dense , TimeDistributed\n",
        "from keras.layers import RepeatVector, Dense, Activation, Lambda , LSTMCell , Reshape , Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model, Model\n",
        "\n",
        "class attention(Layer):\n",
        "    def __init__(self,**kwargs):\n",
        "        super(attention,self).__init__(**kwargs)\n",
        "\n",
        "    def build(self,input_shape):\n",
        "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
        "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
        "        super(attention, self).build(input_shape)\n",
        "\n",
        "    def call(self,x):\n",
        "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
        "        at=K.softmax(et)\n",
        "        at=K.expand_dims(at,axis=-1)\n",
        "        output=x*at\n",
        "        return K.sum(output,axis=1)\n",
        "\n",
        "    def compute_output_shape(self,input_shape):\n",
        "        return (input_shape[0],input_shape[-1])\n",
        "\n",
        "    def get_config(self):\n",
        "        return super(attention,self).get_config()\n",
        "\n",
        "class seq2seqmodel():\n",
        "\n",
        "  def __init__(self, Tx, Ty, rnn_hidden_units, embedding_dims, \n",
        "                 vocab_size, embedding_matrix):\n",
        "      \n",
        "    self.Tx = Tx\n",
        "    self.Ty = Ty\n",
        "    self.rnn_hidden_units = rnn_hidden_units\n",
        "    self.embedding_dims = embedding_dims\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_matrix = embedding_matrix\n",
        "    self.batch_size = batch_size\n",
        "    self.attention_layer = attention()\n",
        "    self.dense_layer = Dense(10 , activation = 'tanh')\n",
        "    self.post_lstm_layer = LSTM(self.rnn_hidden_units, return_state = True)\n",
        "    self.repeator = RepeatVector(self.Tx)\n",
        "    self.concatenator = Concatenate(axis=-1)\n",
        "    self.ouput_layer = Dense(self.vocab_size , activation = 'softmax')\n",
        "\n",
        "  def build(self,\n",
        "            input_shape = None,\n",
        "            output_shape = None):\n",
        "    self.input_shape = input_shape\n",
        "    self.ouput_shape = output_shape\n",
        "\n",
        "\n",
        "    encoder_input = Input(shape = (self.Tx,) , name = \"encoder_input\")\n",
        "    decoder_input = Input(shape = (self.Ty,) , name = \"decoder_input\")\n",
        "    S0 = Input(shape = (self.rnn_hidden_units ,) , name =\"S0\")\n",
        "    C0 = Input(shape = (self.rnn_hidden_units ,) , name = \"C0\")\n",
        "\n",
        "    encoder_embeddings = Embedding(input_dim = self.vocab_size ,\n",
        "                                  output_dim = self.embedding_dims,\n",
        "                                  weights = [self.embedding_matrix], \n",
        "                                  trainable = False)(encoder_input)\n",
        "    \n",
        "    decoder_embeddings = Embedding(input_dim = self.vocab_size,\n",
        "                                  output_dim = self.embedding_dims,\n",
        "                                  weights = [self.embedding_matrix], \n",
        "                                  trainable = False)(decoder_input)\n",
        "    \n",
        "    activations,last_hidden_state,last_cell_state = (LSTM(units = self.rnn_hidden_units,\n",
        "                                                                return_sequences = True,\n",
        "                                                                return_state = True))(encoder_embeddings)\n",
        "\n",
        "    s = last_hidden_state\n",
        "    c = last_cell_state\n",
        "    outputs = []\n",
        "    \n",
        "    for t in range(self.Ty):\n",
        "\n",
        "      repeator = self.repeator(s)\n",
        "      \n",
        "      concat = self.concatenator(inputs = [activations, repeator])\n",
        "      \n",
        "      context = self.attention_layer(inputs = concat)\n",
        "\n",
        "      d_embeddings = Lambda(lambda x: x[:,t,:])(decoder_embeddings)\n",
        "\n",
        "      decoder = self.concatenator(inputs = [context , d_embeddings ])\n",
        "\n",
        "      \n",
        "      decoder = Reshape(target_shape = (1 , 712))(decoder)\n",
        "\n",
        "      s, _ , c = self.post_lstm_layer(inputs = decoder , initial_state = [s ,c])\n",
        "\n",
        "      out = self.ouput_layer(s)\n",
        "\n",
        "      outputs.append(out)\n",
        "\n",
        "    \n",
        "    model = Model(inputs = [encoder_input , decoder_input , S0 , C0] , outputs = outputs )\n",
        "\n",
        "    return model\n",
        "# --------------- model_parameters-----------------------------\n",
        "Tx = 20\n",
        "Ty = 19\n",
        "rnn_hidden_units = 256\n",
        "embedding_dims = 200\n",
        "vocab_size = len(word_index) + 1\n",
        "embedding_matrix = embeddingMatrix\n",
        "dense_units = 256\n",
        "batch_size = 500\n",
        "attention_layer = attention()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H3LITpws8mF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63610cfe-6a3b-49c3-88d5-a59e247d0980"
      },
      "source": [
        "model = seq2seqmodel(Tx, Ty, rnn_hidden_units, embedding_dims, \n",
        "                 vocab_size, embedding_matrix) \n",
        "model =model.build()\n",
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_10 (Embedding)        (None, 20, 200)      2610400     encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_10 (LSTM)                  [(None, 20, 256), (N 467968      embedding_10[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_5 (RepeatVector)  (None, 20, 256)      0           lstm_10[0][1]                    \n",
            "                                                                 lstm_9[0][0]                     \n",
            "                                                                 lstm_9[1][0]                     \n",
            "                                                                 lstm_9[2][0]                     \n",
            "                                                                 lstm_9[3][0]                     \n",
            "                                                                 lstm_9[4][0]                     \n",
            "                                                                 lstm_9[5][0]                     \n",
            "                                                                 lstm_9[6][0]                     \n",
            "                                                                 lstm_9[7][0]                     \n",
            "                                                                 lstm_9[8][0]                     \n",
            "                                                                 lstm_9[9][0]                     \n",
            "                                                                 lstm_9[10][0]                    \n",
            "                                                                 lstm_9[11][0]                    \n",
            "                                                                 lstm_9[12][0]                    \n",
            "                                                                 lstm_9[13][0]                    \n",
            "                                                                 lstm_9[14][0]                    \n",
            "                                                                 lstm_9[15][0]                    \n",
            "                                                                 lstm_9[16][0]                    \n",
            "                                                                 lstm_9[17][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "decoder_input (InputLayer)      (None, 19)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     multiple             0           lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[0][0]            \n",
            "                                                                 attention_9[0][0]                \n",
            "                                                                 lambda_77[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[1][0]            \n",
            "                                                                 attention_9[1][0]                \n",
            "                                                                 lambda_78[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[2][0]            \n",
            "                                                                 attention_9[2][0]                \n",
            "                                                                 lambda_79[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[3][0]            \n",
            "                                                                 attention_9[3][0]                \n",
            "                                                                 lambda_80[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[4][0]            \n",
            "                                                                 attention_9[4][0]                \n",
            "                                                                 lambda_81[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[5][0]            \n",
            "                                                                 attention_9[5][0]                \n",
            "                                                                 lambda_82[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[6][0]            \n",
            "                                                                 attention_9[6][0]                \n",
            "                                                                 lambda_83[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[7][0]            \n",
            "                                                                 attention_9[7][0]                \n",
            "                                                                 lambda_84[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[8][0]            \n",
            "                                                                 attention_9[8][0]                \n",
            "                                                                 lambda_85[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[9][0]            \n",
            "                                                                 attention_9[9][0]                \n",
            "                                                                 lambda_86[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[10][0]           \n",
            "                                                                 attention_9[10][0]               \n",
            "                                                                 lambda_87[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[11][0]           \n",
            "                                                                 attention_9[11][0]               \n",
            "                                                                 lambda_88[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[12][0]           \n",
            "                                                                 attention_9[12][0]               \n",
            "                                                                 lambda_89[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[13][0]           \n",
            "                                                                 attention_9[13][0]               \n",
            "                                                                 lambda_90[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[14][0]           \n",
            "                                                                 attention_9[14][0]               \n",
            "                                                                 lambda_91[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[15][0]           \n",
            "                                                                 attention_9[15][0]               \n",
            "                                                                 lambda_92[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[16][0]           \n",
            "                                                                 attention_9[16][0]               \n",
            "                                                                 lambda_93[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[17][0]           \n",
            "                                                                 attention_9[17][0]               \n",
            "                                                                 lambda_94[0][0]                  \n",
            "                                                                 lstm_10[0][0]                    \n",
            "                                                                 repeat_vector_5[18][0]           \n",
            "                                                                 attention_9[18][0]               \n",
            "                                                                 lambda_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, 19, 200)      2610400     decoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention_9 (attention)         (None, 512)          532         concatenate_5[0][0]              \n",
            "                                                                 concatenate_5[2][0]              \n",
            "                                                                 concatenate_5[4][0]              \n",
            "                                                                 concatenate_5[6][0]              \n",
            "                                                                 concatenate_5[8][0]              \n",
            "                                                                 concatenate_5[10][0]             \n",
            "                                                                 concatenate_5[12][0]             \n",
            "                                                                 concatenate_5[14][0]             \n",
            "                                                                 concatenate_5[16][0]             \n",
            "                                                                 concatenate_5[18][0]             \n",
            "                                                                 concatenate_5[20][0]             \n",
            "                                                                 concatenate_5[22][0]             \n",
            "                                                                 concatenate_5[24][0]             \n",
            "                                                                 concatenate_5[26][0]             \n",
            "                                                                 concatenate_5[28][0]             \n",
            "                                                                 concatenate_5[30][0]             \n",
            "                                                                 concatenate_5[32][0]             \n",
            "                                                                 concatenate_5[34][0]             \n",
            "                                                                 concatenate_5[36][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_77 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_77 (Reshape)            (None, 1, 712)       0           concatenate_5[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   [(None, 256), (None, 992256      reshape_77[0][0]                 \n",
            "                                                                 lstm_10[0][1]                    \n",
            "                                                                 lstm_10[0][2]                    \n",
            "                                                                 reshape_78[0][0]                 \n",
            "                                                                 lstm_9[0][0]                     \n",
            "                                                                 lstm_9[0][2]                     \n",
            "                                                                 reshape_79[0][0]                 \n",
            "                                                                 lstm_9[1][0]                     \n",
            "                                                                 lstm_9[1][2]                     \n",
            "                                                                 reshape_80[0][0]                 \n",
            "                                                                 lstm_9[2][0]                     \n",
            "                                                                 lstm_9[2][2]                     \n",
            "                                                                 reshape_81[0][0]                 \n",
            "                                                                 lstm_9[3][0]                     \n",
            "                                                                 lstm_9[3][2]                     \n",
            "                                                                 reshape_82[0][0]                 \n",
            "                                                                 lstm_9[4][0]                     \n",
            "                                                                 lstm_9[4][2]                     \n",
            "                                                                 reshape_83[0][0]                 \n",
            "                                                                 lstm_9[5][0]                     \n",
            "                                                                 lstm_9[5][2]                     \n",
            "                                                                 reshape_84[0][0]                 \n",
            "                                                                 lstm_9[6][0]                     \n",
            "                                                                 lstm_9[6][2]                     \n",
            "                                                                 reshape_85[0][0]                 \n",
            "                                                                 lstm_9[7][0]                     \n",
            "                                                                 lstm_9[7][2]                     \n",
            "                                                                 reshape_86[0][0]                 \n",
            "                                                                 lstm_9[8][0]                     \n",
            "                                                                 lstm_9[8][2]                     \n",
            "                                                                 reshape_87[0][0]                 \n",
            "                                                                 lstm_9[9][0]                     \n",
            "                                                                 lstm_9[9][2]                     \n",
            "                                                                 reshape_88[0][0]                 \n",
            "                                                                 lstm_9[10][0]                    \n",
            "                                                                 lstm_9[10][2]                    \n",
            "                                                                 reshape_89[0][0]                 \n",
            "                                                                 lstm_9[11][0]                    \n",
            "                                                                 lstm_9[11][2]                    \n",
            "                                                                 reshape_90[0][0]                 \n",
            "                                                                 lstm_9[12][0]                    \n",
            "                                                                 lstm_9[12][2]                    \n",
            "                                                                 reshape_91[0][0]                 \n",
            "                                                                 lstm_9[13][0]                    \n",
            "                                                                 lstm_9[13][2]                    \n",
            "                                                                 reshape_92[0][0]                 \n",
            "                                                                 lstm_9[14][0]                    \n",
            "                                                                 lstm_9[14][2]                    \n",
            "                                                                 reshape_93[0][0]                 \n",
            "                                                                 lstm_9[15][0]                    \n",
            "                                                                 lstm_9[15][2]                    \n",
            "                                                                 reshape_94[0][0]                 \n",
            "                                                                 lstm_9[16][0]                    \n",
            "                                                                 lstm_9[16][2]                    \n",
            "                                                                 reshape_95[0][0]                 \n",
            "                                                                 lstm_9[17][0]                    \n",
            "                                                                 lstm_9[17][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_78 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_78 (Reshape)            (None, 1, 712)       0           concatenate_5[3][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_79 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_79 (Reshape)            (None, 1, 712)       0           concatenate_5[5][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_80 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_80 (Reshape)            (None, 1, 712)       0           concatenate_5[7][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_81 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_81 (Reshape)            (None, 1, 712)       0           concatenate_5[9][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lambda_82 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_82 (Reshape)            (None, 1, 712)       0           concatenate_5[11][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_83 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_83 (Reshape)            (None, 1, 712)       0           concatenate_5[13][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_84 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_84 (Reshape)            (None, 1, 712)       0           concatenate_5[15][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_85 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_85 (Reshape)            (None, 1, 712)       0           concatenate_5[17][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_86 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_86 (Reshape)            (None, 1, 712)       0           concatenate_5[19][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_87 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_87 (Reshape)            (None, 1, 712)       0           concatenate_5[21][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_88 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_88 (Reshape)            (None, 1, 712)       0           concatenate_5[23][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_89 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_89 (Reshape)            (None, 1, 712)       0           concatenate_5[25][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_90 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_90 (Reshape)            (None, 1, 712)       0           concatenate_5[27][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_91 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_91 (Reshape)            (None, 1, 712)       0           concatenate_5[29][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_92 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_92 (Reshape)            (None, 1, 712)       0           concatenate_5[31][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_93 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_93 (Reshape)            (None, 1, 712)       0           concatenate_5[33][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_94 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_94 (Reshape)            (None, 1, 712)       0           concatenate_5[35][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda_95 (Lambda)              (None, 200)          0           embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "reshape_95 (Reshape)            (None, 1, 712)       0           concatenate_5[37][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 13052)        3354364     lstm_9[0][0]                     \n",
            "                                                                 lstm_9[1][0]                     \n",
            "                                                                 lstm_9[2][0]                     \n",
            "                                                                 lstm_9[3][0]                     \n",
            "                                                                 lstm_9[4][0]                     \n",
            "                                                                 lstm_9[5][0]                     \n",
            "                                                                 lstm_9[6][0]                     \n",
            "                                                                 lstm_9[7][0]                     \n",
            "                                                                 lstm_9[8][0]                     \n",
            "                                                                 lstm_9[9][0]                     \n",
            "                                                                 lstm_9[10][0]                    \n",
            "                                                                 lstm_9[11][0]                    \n",
            "                                                                 lstm_9[12][0]                    \n",
            "                                                                 lstm_9[13][0]                    \n",
            "                                                                 lstm_9[14][0]                    \n",
            "                                                                 lstm_9[15][0]                    \n",
            "                                                                 lstm_9[16][0]                    \n",
            "                                                                 lstm_9[17][0]                    \n",
            "                                                                 lstm_9[18][0]                    \n",
            "==================================================================================================\n",
            "Total params: 10,035,920\n",
            "Trainable params: 4,815,120\n",
            "Non-trainable params: 5,220,800\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7XKsqOltBDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Adam(lr = 0.005, beta_1 = 0.9,beta_2 = 0.999 , decay = 0.01)\n",
        "model.compile(optimizer = opt , loss = \"sparse_categorical_crossentropy\" ,metrics = ['accuracy'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNdoeSYptCwi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "outputId": "38261626-6a1d-4041-92c5-f919a5b8e03b"
      },
      "source": [
        "model.fit([context , response1, np.zeros((batch_size , rnn_hidden_units)) , np.zeros((batch_size , rnn_hidden_units))] , response2 , epochs = 100 , batch_size = 10)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - 40s 80ms/step - loss: 88.0745 - dense_10_loss: 2.6429 - dense_10_accuracy: 0.0200 - dense_10_accuracy_1: 0.0180 - dense_10_accuracy_2: 0.0140 - dense_10_accuracy_3: 0.0540 - dense_10_accuracy_4: 0.1080 - dense_10_accuracy_5: 0.1660 - dense_10_accuracy_6: 0.2460 - dense_10_accuracy_7: 0.3240 - dense_10_accuracy_8: 0.3740 - dense_10_accuracy_9: 0.4240 - dense_10_accuracy_10: 0.4640 - dense_10_accuracy_11: 0.5120 - dense_10_accuracy_12: 0.5600 - dense_10_accuracy_13: 0.5940 - dense_10_accuracy_14: 0.6380 - dense_10_accuracy_15: 0.6560 - dense_10_accuracy_16: 0.6720 - dense_10_accuracy_17: 0.6920 - dense_10_accuracy_18: 0.7360\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 30s 61ms/step - loss: 65.7192 - dense_10_loss: 1.5060 - dense_10_accuracy: 0.0940 - dense_10_accuracy_1: 0.1040 - dense_10_accuracy_2: 0.1400 - dense_10_accuracy_3: 0.1820 - dense_10_accuracy_4: 0.2400 - dense_10_accuracy_5: 0.2940 - dense_10_accuracy_6: 0.3600 - dense_10_accuracy_7: 0.4280 - dense_10_accuracy_8: 0.4580 - dense_10_accuracy_9: 0.5160 - dense_10_accuracy_10: 0.5360 - dense_10_accuracy_11: 0.5980 - dense_10_accuracy_12: 0.6500 - dense_10_accuracy_13: 0.6720 - dense_10_accuracy_14: 0.7060 - dense_10_accuracy_15: 0.7140 - dense_10_accuracy_16: 0.7340 - dense_10_accuracy_17: 0.7260 - dense_10_accuracy_18: 0.7600\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 31s 61ms/step - loss: 63.4132 - dense_10_loss: 1.4303 - dense_10_accuracy: 0.0960 - dense_10_accuracy_1: 0.1040 - dense_10_accuracy_2: 0.1400 - dense_10_accuracy_3: 0.1820 - dense_10_accuracy_4: 0.2400 - dense_10_accuracy_5: 0.2940 - dense_10_accuracy_6: 0.3600 - dense_10_accuracy_7: 0.4280 - dense_10_accuracy_8: 0.4580 - dense_10_accuracy_9: 0.5160 - dense_10_accuracy_10: 0.5360 - dense_10_accuracy_11: 0.5980 - dense_10_accuracy_12: 0.6500 - dense_10_accuracy_13: 0.6720 - dense_10_accuracy_14: 0.7060 - dense_10_accuracy_15: 0.7160 - dense_10_accuracy_16: 0.7440 - dense_10_accuracy_17: 0.7340 - dense_10_accuracy_18: 0.7760\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 62.2524 - dense_10_loss: 1.3573 - dense_10_accuracy: 0.1060 - dense_10_accuracy_1: 0.1040 - dense_10_accuracy_2: 0.1400 - dense_10_accuracy_3: 0.1820 - dense_10_accuracy_4: 0.2400 - dense_10_accuracy_5: 0.2940 - dense_10_accuracy_6: 0.3600 - dense_10_accuracy_7: 0.4280 - dense_10_accuracy_8: 0.4580 - dense_10_accuracy_9: 0.5160 - dense_10_accuracy_10: 0.5360 - dense_10_accuracy_11: 0.5980 - dense_10_accuracy_12: 0.6500 - dense_10_accuracy_13: 0.6720 - dense_10_accuracy_14: 0.7060 - dense_10_accuracy_15: 0.7160 - dense_10_accuracy_16: 0.7440 - dense_10_accuracy_17: 0.7340 - dense_10_accuracy_18: 0.7780\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 61.3403 - dense_10_loss: 1.3448 - dense_10_accuracy: 0.1060 - dense_10_accuracy_1: 0.1040 - dense_10_accuracy_2: 0.1400 - dense_10_accuracy_3: 0.1820 - dense_10_accuracy_4: 0.2400 - dense_10_accuracy_5: 0.2940 - dense_10_accuracy_6: 0.3600 - dense_10_accuracy_7: 0.4280 - dense_10_accuracy_8: 0.4580 - dense_10_accuracy_9: 0.5160 - dense_10_accuracy_10: 0.5360 - dense_10_accuracy_11: 0.5980 - dense_10_accuracy_12: 0.6500 - dense_10_accuracy_13: 0.6740 - dense_10_accuracy_14: 0.7060 - dense_10_accuracy_15: 0.7160 - dense_10_accuracy_16: 0.7420 - dense_10_accuracy_17: 0.7440 - dense_10_accuracy_18: 0.7780\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 29s 57ms/step - loss: 60.5886 - dense_10_loss: 1.3065 - dense_10_accuracy: 0.1060 - dense_10_accuracy_1: 0.1060 - dense_10_accuracy_2: 0.1380 - dense_10_accuracy_3: 0.1820 - dense_10_accuracy_4: 0.2380 - dense_10_accuracy_5: 0.2960 - dense_10_accuracy_6: 0.3620 - dense_10_accuracy_7: 0.4280 - dense_10_accuracy_8: 0.4520 - dense_10_accuracy_9: 0.5120 - dense_10_accuracy_10: 0.5360 - dense_10_accuracy_11: 0.5960 - dense_10_accuracy_12: 0.6560 - dense_10_accuracy_13: 0.6720 - dense_10_accuracy_14: 0.7040 - dense_10_accuracy_15: 0.7200 - dense_10_accuracy_16: 0.7460 - dense_10_accuracy_17: 0.7460 - dense_10_accuracy_18: 0.7760\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 29s 58ms/step - loss: 59.8062 - dense_10_loss: 1.2620 - dense_10_accuracy: 0.1020 - dense_10_accuracy_1: 0.1060 - dense_10_accuracy_2: 0.1400 - dense_10_accuracy_3: 0.1820 - dense_10_accuracy_4: 0.2400 - dense_10_accuracy_5: 0.2940 - dense_10_accuracy_6: 0.3580 - dense_10_accuracy_7: 0.4280 - dense_10_accuracy_8: 0.4560 - dense_10_accuracy_9: 0.5220 - dense_10_accuracy_10: 0.5360 - dense_10_accuracy_11: 0.5980 - dense_10_accuracy_12: 0.6500 - dense_10_accuracy_13: 0.6720 - dense_10_accuracy_14: 0.7040 - dense_10_accuracy_15: 0.7160 - dense_10_accuracy_16: 0.7440 - dense_10_accuracy_17: 0.7480 - dense_10_accuracy_18: 0.7840\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 59.0070 - dense_10_loss: 1.2434 - dense_10_accuracy: 0.1060 - dense_10_accuracy_1: 0.1100 - dense_10_accuracy_2: 0.1380 - dense_10_accuracy_3: 0.1800 - dense_10_accuracy_4: 0.2420 - dense_10_accuracy_5: 0.2920 - dense_10_accuracy_6: 0.3620 - dense_10_accuracy_7: 0.4480 - dense_10_accuracy_8: 0.4780 - dense_10_accuracy_9: 0.5200 - dense_10_accuracy_10: 0.5400 - dense_10_accuracy_11: 0.5980 - dense_10_accuracy_12: 0.6480 - dense_10_accuracy_13: 0.6840 - dense_10_accuracy_14: 0.7060 - dense_10_accuracy_15: 0.7080 - dense_10_accuracy_16: 0.7420 - dense_10_accuracy_17: 0.7600 - dense_10_accuracy_18: 0.7860\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 30s 59ms/step - loss: 58.4994 - dense_10_loss: 1.2212 - dense_10_accuracy: 0.1020 - dense_10_accuracy_1: 0.1080 - dense_10_accuracy_2: 0.1400 - dense_10_accuracy_3: 0.1740 - dense_10_accuracy_4: 0.2340 - dense_10_accuracy_5: 0.3040 - dense_10_accuracy_6: 0.3660 - dense_10_accuracy_7: 0.4360 - dense_10_accuracy_8: 0.4860 - dense_10_accuracy_9: 0.5300 - dense_10_accuracy_10: 0.5340 - dense_10_accuracy_11: 0.6060 - dense_10_accuracy_12: 0.6600 - dense_10_accuracy_13: 0.6860 - dense_10_accuracy_14: 0.7040 - dense_10_accuracy_15: 0.7140 - dense_10_accuracy_16: 0.7480 - dense_10_accuracy_17: 0.7640 - dense_10_accuracy_18: 0.7860\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 29s 59ms/step - loss: 57.8701 - dense_10_loss: 1.2068 - dense_10_accuracy: 0.1040 - dense_10_accuracy_1: 0.0980 - dense_10_accuracy_2: 0.1400 - dense_10_accuracy_3: 0.1860 - dense_10_accuracy_4: 0.2380 - dense_10_accuracy_5: 0.3040 - dense_10_accuracy_6: 0.3780 - dense_10_accuracy_7: 0.4520 - dense_10_accuracy_8: 0.4780 - dense_10_accuracy_9: 0.5160 - dense_10_accuracy_10: 0.5400 - dense_10_accuracy_11: 0.6120 - dense_10_accuracy_12: 0.6500 - dense_10_accuracy_13: 0.6740 - dense_10_accuracy_14: 0.7000 - dense_10_accuracy_15: 0.7060 - dense_10_accuracy_16: 0.7480 - dense_10_accuracy_17: 0.7640 - dense_10_accuracy_18: 0.7860\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 57.2679 - dense_10_loss: 1.1886 - dense_10_accuracy: 0.0980 - dense_10_accuracy_1: 0.1040 - dense_10_accuracy_2: 0.1500 - dense_10_accuracy_3: 0.1820 - dense_10_accuracy_4: 0.2600 - dense_10_accuracy_5: 0.3240 - dense_10_accuracy_6: 0.3900 - dense_10_accuracy_7: 0.4500 - dense_10_accuracy_8: 0.4820 - dense_10_accuracy_9: 0.5340 - dense_10_accuracy_10: 0.5560 - dense_10_accuracy_11: 0.6160 - dense_10_accuracy_12: 0.6600 - dense_10_accuracy_13: 0.6900 - dense_10_accuracy_14: 0.7000 - dense_10_accuracy_15: 0.7120 - dense_10_accuracy_16: 0.7500 - dense_10_accuracy_17: 0.7640 - dense_10_accuracy_18: 0.7860\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 30s 60ms/step - loss: 56.7862 - dense_10_loss: 1.1832 - dense_10_accuracy: 0.1060 - dense_10_accuracy_1: 0.1260 - dense_10_accuracy_2: 0.1420 - dense_10_accuracy_3: 0.1880 - dense_10_accuracy_4: 0.2540 - dense_10_accuracy_5: 0.3160 - dense_10_accuracy_6: 0.3860 - dense_10_accuracy_7: 0.4600 - dense_10_accuracy_8: 0.4820 - dense_10_accuracy_9: 0.5200 - dense_10_accuracy_10: 0.5440 - dense_10_accuracy_11: 0.6260 - dense_10_accuracy_12: 0.6540 - dense_10_accuracy_13: 0.6820 - dense_10_accuracy_14: 0.6980 - dense_10_accuracy_15: 0.7180 - dense_10_accuracy_16: 0.7540 - dense_10_accuracy_17: 0.7620 - dense_10_accuracy_18: 0.7860\n",
            "Epoch 13/100\n",
            "260/500 [==============>...............] - ETA: 14s - loss: 54.3055 - dense_10_loss: 1.1145 - dense_10_accuracy: 0.1192 - dense_10_accuracy_1: 0.1154 - dense_10_accuracy_2: 0.1462 - dense_10_accuracy_3: 0.2077 - dense_10_accuracy_4: 0.2615 - dense_10_accuracy_5: 0.3269 - dense_10_accuracy_6: 0.3923 - dense_10_accuracy_7: 0.4846 - dense_10_accuracy_8: 0.5231 - dense_10_accuracy_9: 0.5962 - dense_10_accuracy_10: 0.5846 - dense_10_accuracy_11: 0.6615 - dense_10_accuracy_12: 0.6654 - dense_10_accuracy_13: 0.7038 - dense_10_accuracy_14: 0.7231 - dense_10_accuracy_15: 0.7231 - dense_10_accuracy_16: 0.7654 - dense_10_accuracy_17: 0.7692 - dense_10_accuracy_18: 0.7885"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-e9860b2bea50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mresponse1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mrnn_hidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mrnn_hidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mresponse2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr6Vsl9ZthDi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d463a542-4ed5-4117-ff12-13025ef4ff29"
      },
      "source": [
        "s = ['<start> do you support congress <end>']\n",
        "r= ['<start> yes i do , you should also support congress <end>']\n",
        "\n",
        "seq = tokenizer.texts_to_sequences(s)\n",
        "pad = pad_sequences(seq,maxlen=max_len, truncating=trunc_token,padding = 'post')\n",
        "\n",
        "seq = tokenizer.texts_to_sequences(r)\n",
        "pad2 = pad_sequences(seq,maxlen=max_len, truncating=trunc_token,padding = 'post')\n",
        "\n",
        "pad2 = pad2[:,:-1]\n",
        "\n",
        "print(pad)\n",
        "\n",
        "pred = model.predict([pad , pad2 , np.zeros((1, rnn_hidden_units)) , np.zeros((1,rnn_hidden_units))])\n",
        "\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   3   27    6 2119 8067    4    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4JhkARQtk8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def beam_search_decoder(predictions, top_k = 3):\n",
        "\n",
        "    output_sequences = [([], 0)]\n",
        "    \n",
        "    for token_probs in predictions:\n",
        "        new_sequences = []\n",
        "        token_probs = token_probs.reshape(len(word_index)+1 ,)\n",
        "        for old_seq, old_score in output_sequences:\n",
        "            for char_index in range(len(token_probs)):\n",
        "                new_seq = old_seq + [char_index]\n",
        "                new_score = old_score + math.log(token_probs[char_index])\n",
        "                new_sequences.append((new_seq, new_score))\n",
        "                \n",
        "        output_sequences = sorted(new_sequences, key = lambda val: val[1], reverse = True)\n",
        "        output_sequences = output_sequences[:top_k]\n",
        "        \n",
        "    return output_sequences"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UzUTLhwtm0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8732472a-9fb0-47f3-bf44-b2301d2e2d65"
      },
      "source": [
        "ans = beam_search_decoder(pred)\n",
        "print(ans)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[([8, 5, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], -21.46504867779595), ([8, 5, 5, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], -21.636926359382915), ([8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], -21.853577822239643)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haFIqM1-txWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 46,
      "outputs": []
    }
  ]
}