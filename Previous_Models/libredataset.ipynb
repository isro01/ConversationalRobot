{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import csv\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.callbacks import Callback\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.keras.activations import relu\n",
    "from tensorflow.python.keras.metrics import categorical_accuracy, mean_squared_error\n",
    "from tensorflow.python.keras.callbacks import BaseLogger, ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.initializers import Ones, Zeros, glorot_normal\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "# from data_genration import DataGenerator\n",
    "\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_relu(x):\n",
    "    return relu(x, max_value=20)\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    labels, y_pred, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def ctc(y_true, y_pred):\n",
    "    return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speech_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Batch normalize the input\n",
    "    model.add(BatchNormalization(axis=-1, input_shape=(None, 128), name='BN_1'))\n",
    "    \n",
    "    # 1D Convs\n",
    "    model.add(Conv1D(512, 5, strides=1, activation=clipped_relu, name='Conv1D_1'))\n",
    "    model.add(Conv1D(512, 5, strides=1, activation=clipped_relu, name='Conv1D_2'))\n",
    "    model.add(Conv1D(512, 5, strides=2, activation=clipped_relu, name='Conv1D_3'))\n",
    "    \n",
    "    # Batch Normalization\n",
    "    model.add(BatchNormalization(axis=-1, name='BN_2'))\n",
    "    \n",
    "    # BiRNNs\n",
    "    model.add(Bidirectional(SimpleRNN(1280, return_sequences=True, name='BiRNN_1'), merge_mode='sum'))\n",
    "    model.add(Bidirectional(SimpleRNN(1280, return_sequences=True, name='BiRNN_2'), merge_mode='sum'))\n",
    "    model.add(Bidirectional(SimpleRNN(1280, return_sequences=True, name='BiRNN_3'), merge_mode='sum'))\n",
    "    model.add(Bidirectional(SimpleRNN(1280, return_sequences=True, name='BiRNN_4'), merge_mode='sum'))\n",
    "    model.add(Bidirectional(SimpleRNN(1280, return_sequences=True, name='BiRNN_5'), merge_mode='sum'))\n",
    "    model.add(Bidirectional(SimpleRNN(1280, return_sequences=True, name='BiRNN_6'), merge_mode='sum'))\n",
    "    model.add(Bidirectional(SimpleRNN(1280, return_sequences=True, name='BiRNN_7'), merge_mode='sum'))\n",
    "    \n",
    "    # Batch Normalization\n",
    "    model.add(BatchNormalization(axis=-1, name='BN_3'))\n",
    "    \n",
    "    # FC\n",
    "    model.add(TimeDistributed(Dense(1024, activation=clipped_relu, name='FC1')))\n",
    "    model.add(TimeDistributed(Dense(29, activation='softmax', name='y_pred')))\n",
    "    return model\n",
    "\n",
    "def get_trainable_speech_model():\n",
    "    model = get_speech_model()\n",
    "    y_pred = model.outputs[0]\n",
    "    model_input = model.inputs[0]\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    labels = Input(name='the_labels', shape=[None,], dtype='int32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int32')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int32')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, name='ctc')([labels, y_pred, input_length, label_length])\n",
    "    trainable_model = Model(inputs=[model_input, labels, input_length, label_length], outputs=loss_out)\n",
    "    return trainable_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "BN_1 (BatchNormalization)    (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "Conv1D_1 (Conv1D)            (None, None, 512)         328192    \n",
      "_________________________________________________________________\n",
      "Conv1D_2 (Conv1D)            (None, None, 512)         1311232   \n",
      "_________________________________________________________________\n",
      "Conv1D_3 (Conv1D)            (None, None, 512)         1311232   \n",
      "_________________________________________________________________\n",
      "BN_2 (BatchNormalization)    (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 1280)        4590080   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 1280)        6556160   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 1280)        6556160   \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, None, 1280)        6556160   \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, None, 1280)        6556160   \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, None, 1280)        6556160   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, None, 1280)        6556160   \n",
      "_________________________________________________________________\n",
      "BN_3 (BatchNormalization)    (None, None, 1280)        5120      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 1024)        1311744   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 29)          29725     \n",
      "=================================================================\n",
      "Total params: 48,226,845\n",
      "Trainable params: 48,223,005\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "BN_1_input (InputLayer)         [(None, None, 128)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "BN_1 (BatchNormalization)       (None, None, 128)    512         BN_1_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_1 (Conv1D)               (None, None, 512)    328192      BN_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_2 (Conv1D)               (None, None, 512)    1311232     Conv1D_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_3 (Conv1D)               (None, None, 512)    1311232     Conv1D_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "BN_2 (BatchNormalization)       (None, None, 512)    2048        Conv1D_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, None, 1280)   4590080     BN_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 1280)   6556160     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 1280)   6556160     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 1280)   6556160     bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 1280)   6556160     bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, None, 1280)   6556160     bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 1280)   6556160     bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BN_3 (BatchNormalization)       (None, None, 1280)   5120        bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 1024)   1311744     BN_3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 29)     29725       time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           the_labels[0][0]                 \n",
      "                                                                 time_distributed_1[0][0]         \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 48,226,845\n",
      "Trainable params: 48,223,005\n",
      "Non-trainable params: 3,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_trainable_speech_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/varun/Desktop/speechReco'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/varun/Desktop/speechReco/data'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/varun/Desktop/speechReco/data'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/.local/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import librosa   #for audio processing\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from scipy.io import wavfile #for audio processing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_spectrogram(wav_file):\n",
    "    rate, data = get_wav_info(wav_file)\n",
    "    nfft = 200 # Length of each window segment\n",
    "    fs = 8000 # Sampling frequencies\n",
    "    noverlap = 120 # Overlap between windows\n",
    "    nchannels = data.ndim\n",
    "    if nchannels == 1:\n",
    "        pxx, freqs, bins, im = plt.specgram(data, nfft, fs, noverlap = noverlap)\n",
    "    elif nchannels == 2:\n",
    "        pxx, freqs, bins, im = plt.specgram(data[:,0], nfft, fs, noverlap = noverlap)\n",
    "    return pxx\n",
    "\n",
    "# Load a wav file\n",
    "def get_wav_info(wav_file):\n",
    "    data,rate = sf.read(wav_file)\n",
    "    return rate, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "file_names = []\n",
    "samples = []\n",
    "\n",
    "for direc in os.listdir(path):\n",
    "    for subdir in os.listdir(path +\"/\" + direc):\n",
    "        file = [ f for f in os.listdir(path + '/' + direc + \"/\" + subdir) if f.endswith('.txt')]\n",
    "        for f in file:\n",
    "            with open(path + \"/\" + direc + \"/\" + subdir  +'/' +f ,'r') as txtfile:\n",
    "                data = txtfile.read()\n",
    "                sentence = data.lower().split('\\n')\n",
    "                for sent in sentence:\n",
    "                    sent = sent.split(\" \",1)\n",
    "                    if len(sent) == 2:\n",
    "                        file_names.append(sent[0])\n",
    "                        sample = graph_spectrogram(path + \"/\" + direc + \"/\" + subdir  +'/'+ sent[0] +'.flac')\n",
    "                        samples.append(sample)\n",
    "                        labels.append(sent[1])\n",
    "                        \n",
    "                    elif len(samples) > 10:\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
