{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/.local/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile #for audio processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model , Sequential\n",
    "from keras.utils import Sequence\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/varun/Desktop/speechReco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/varun/Desktop/speechReco'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data1'\n",
    "os.chdir(os.getcwd() +path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/varun/Desktop/speechReco/data1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence', 'house', 'nine', 'four', 'happy', 'wow', 'five', 'zero', 'tree', 'six', 'one', 'three', 'eight', 'cat', 'two', 'seven', 'marvin', 'dog', 'sheila', 'bed', 'bird']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label = 23 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_map_str = \"\"\"\n",
    "<SPACE> 0\n",
    "a 1\n",
    "b 2\n",
    "c 3\n",
    "d 4\n",
    "e 5\n",
    "f 6\n",
    "g 7\n",
    "h 8\n",
    "i 9\n",
    "j 10\n",
    "k 11\n",
    "l 12\n",
    "m 13\n",
    "n 14\n",
    "o 15\n",
    "p 16\n",
    "q 17\n",
    "r 18\n",
    "s 19\n",
    "t 20\n",
    "u 21\n",
    "v 22\n",
    "w 23\n",
    "x 24\n",
    "y 25\n",
    "z 26\n",
    "' 27\n",
    "\"\"\"\n",
    "\n",
    "char_map = {}\n",
    "index_map = {}\n",
    "\n",
    "for line in char_map_str.strip().split('\\n'):\n",
    "    ch, index = line.split()\n",
    "    char_map[ch] = int(index)\n",
    "    index_map[int(index)] = ch\n",
    "\n",
    "index_map[0] = ' '\n",
    "def get_label(Y , max_label):\n",
    "    new = []\n",
    "    for c in Y:\n",
    "        if c not in char_map:\n",
    "            continue\n",
    "        elif c == \"'\":\n",
    "            continue\n",
    "        else:\n",
    "            ch = char_map[c]\n",
    "            new.append(ch)\n",
    " \n",
    "    while(len(new) < max_label):\n",
    "        new.append(27)\n",
    "    label = np.array(new)\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go/80fe1dc7_nohash_0.wav\n"
     ]
    }
   ],
   "source": [
    "list_IDs = []\n",
    "\n",
    "for direc in os.listdir():\n",
    "        file = [ f for f in os.listdir(os.getcwd() + '/' + direc ) if f.endswith('.wav')]\n",
    "        for f in file:\n",
    "            list_IDs.append(direc + '/' + f)\n",
    "\n",
    "print((list_IDs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_spectrogram(wav_file):\n",
    "    rate, data = get_wav_info(wav_file)\n",
    "    nfft = 200 # Length of each window segment\n",
    "    fs = 8000 # Sampling frequencies\n",
    "    noverlap = 120 # Overlap between windows\n",
    "    nchannels = data.ndim\n",
    "    if nchannels == 1:\n",
    "        pxx, freqs, bins, im = plt.specgram(data, nfft, fs, noverlap = noverlap)\n",
    "    elif nchannels == 2:\n",
    "        pxx, freqs, bins, im = plt.specgram(data[:,0], nfft, fs, noverlap = noverlap)\n",
    "    return pxx\n",
    "\n",
    "# Load a wav file\n",
    "def get_wav_info(wav_file):\n",
    "    rate , data = wavfile.read(wav_file)\n",
    "    return rate, data\n",
    "\n",
    "def modify_spectrogram_shape(sample ,shape = (101,198) ):\n",
    "    a = np.zeros(shape)\n",
    "    a[: , :sample.shape[1]] = sample\n",
    "    return sample\n",
    "\n",
    "def add_noise(sample , noise_factor):\n",
    "    noise = np.random.randn(sample.shape)\n",
    "    augmented_data = sample + noise_factor * noise\n",
    "    augmented_data = augmented_data.astype(type(sample[0]))\n",
    "    return augmented_data\n",
    "\n",
    "def normalise_spectrogram(sample):\n",
    "    mean = np.mean(sample, axis=0)\n",
    "    std = np.std(sample, axis=0)\n",
    "    sample = (sample - mean) / std\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, all_classes, list_IDs, max_label, batch_size=32, noise_factor = 0.1 , add_noise = False , normalise = False ,dim=(101,198),\n",
    "                 shuffle=True ):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.all_classes = all_classes\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.noise_factor = noise_factor\n",
    "        self.add_noise = add_noise\n",
    "        self.normalise = normalise\n",
    "        self.max_label = max_label\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, labels = self.__data_generation(list_IDs_temp)\n",
    "        \n",
    "        input_length = np.array([self.max_label for _ in range(self.batch_size)])\n",
    "        label_length = np.array([self.max_label for _ in range(self.batch_size)])\n",
    "\n",
    "        return X.shape, labels.shape , input_length.shape , label_length.shape\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim ))\n",
    "        y = np.empty((self.batch_size , max_label ), dtype=int)\n",
    "        \n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            \n",
    "            sample = graph_spectrogram(os.getcwd() + '/' + ID)\n",
    "            if(sample.shape != self.dim):\n",
    "                a = np.zeros(self.dim)\n",
    "                a[: , :sample.shape[1]] = sample\n",
    "                sample = a    \n",
    "            if(self.add_noise):\n",
    "                sample = add_noise(sample , self.noise_factor)\n",
    "            if(self.normalise):\n",
    "                sample = normalise_spectrogram(sample)\n",
    "                \n",
    "            X[i,] = sample\n",
    "\n",
    "            # Store label\n",
    "            y[i,] = get_label(ID.split('/')[0] , self.max_label)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(all_classes ,list_IDs, 23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
