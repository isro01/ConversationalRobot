{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/.local/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile #for audio processing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model , Sequential\n",
    "from keras.utils import Sequence\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/varun/Desktop/speechReco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/varun/Desktop/speechReco'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/varun/Desktop/speechReco/data1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-788a6e197743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/data1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/varun/Desktop/speechReco/data1'"
     ]
    }
   ],
   "source": [
    "path = '/data1'\n",
    "os.chdir(os.getcwd() +path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence', 'house', 'nine', 'four', 'happy', 'wow', 'five', 'zero', 'tree', 'six', 'one', 'three', 'eight', 'cat', 'two', 'seven', 'marvin', 'dog', 'sheila', 'bed', 'bird']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label = 23 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_map_str = \"\"\"\n",
    "<SPACE> 0\n",
    "a 1\n",
    "b 2\n",
    "c 3\n",
    "d 4\n",
    "e 5\n",
    "f 6\n",
    "g 7\n",
    "h 8\n",
    "i 9\n",
    "j 10\n",
    "k 11\n",
    "l 12\n",
    "m 13\n",
    "n 14\n",
    "o 15\n",
    "p 16\n",
    "q 17\n",
    "r 18\n",
    "s 19\n",
    "t 20\n",
    "u 21\n",
    "v 22\n",
    "w 23\n",
    "x 24\n",
    "y 25\n",
    "z 26\n",
    "_ 27\n",
    "\"\"\"\n",
    "\n",
    "char_map = {}\n",
    "index_map = {}\n",
    "\n",
    "for line in char_map_str.strip().split('\\n'):\n",
    "    ch, index = line.split()\n",
    "    if ch == \"<SPACE>\":\n",
    "        ch = \" \"\n",
    "    char_map[ch] = int(index)\n",
    "    index_map[int(index)] = ch\n",
    "\n",
    "index_map[0] = ' '\n",
    "def get_label(Y , max_label):\n",
    "    new = [] \n",
    "    for c in Y:\n",
    "        if c not in char_map:\n",
    "            continue\n",
    "        elif c == \"_\":\n",
    "            continue\n",
    "        else:\n",
    "            ch = char_map[c]\n",
    "            new.append(ch)\n",
    " \n",
    "    while(len(new) < max_label):\n",
    "        new.append(27)\n",
    "    label = np.array(new)\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_IDs = []\n",
    "\n",
    "for direc in os.listdir():\n",
    "        file = [ f for f in os.listdir(os.getcwd() + '/' + direc ) if f.endswith('.wav')]\n",
    "        for f in file:\n",
    "            list_IDs.append(direc + '/' + f)\n",
    "\n",
    "print(\"string :\",len(list_IDs))\n",
    "print((list_IDs[0]),\"\\n\",(list_IDs[500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, all_classes, list_IDs, max_label, char_map, total_timedistributed_output = 101, \n",
    "                 batch_size = 100, noise_factor = 0.1 , add_noise = False , normalise = False ,\n",
    "                 dim = (101,594) ,shuffle = True ):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.all_classes = all_classes\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.noise_factor = noise_factor\n",
    "        self.add_noise = add_noise\n",
    "        self.normalise = normalise\n",
    "        self.max_label = max_label\n",
    "        self.char_map  = char_map\n",
    "        self.total_timedistributed_output = total_timedistributed_output\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        'Denotes the number of batches per epoch'\n",
    "#         return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "        return 100\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        \n",
    "        input_length = np.array([self.total_timedistributed_output for _ in range(self.batch_size)])\n",
    "        label_length = np.array([self.max_label for _ in range(self.batch_size)])\n",
    "        \n",
    "        inputs = {\"the_inputs\": X, \"the_labels\": y, \"input_length\":input_length, \"label_length\": label_length}\n",
    "        outputs = {\"ctc\": y}\n",
    "        return (inputs, outputs)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size , max_label ), dtype=int)\n",
    "        \n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            \n",
    "            index_2 = random.randint(0,len(list_IDs_temp)-1)\n",
    "            index_3 = random.randint(0,len(list_IDs_temp)-1)\n",
    "            \n",
    "            sample_1 = self.__graph_spectrogram(os.getcwd() + '/' + ID)\n",
    "            sample_2 = self.__graph_spectrogram(os.getcwd() + '/' + list_IDs_temp[index_2])\n",
    "            sample_3 = self.__graph_spectrogram(os.getcwd() + '/' + list_IDs_temp[index_3])\n",
    "            \n",
    "            sample = np.concatenate([sample_1 , sample_2 , sample_3] , axis =1 )\n",
    "            \n",
    "            if(sample.shape != self.dim):\n",
    "                a = np.zeros(self.dim)\n",
    "                if(sample.shape[1] < 594):\n",
    "                    a[: , :sample.shape[1]] = sample\n",
    "                sample = a    \n",
    "            if(self.add_noise):\n",
    "                sample = self.__add_noise(sample , self.noise_factor)\n",
    "            if(self.normalise):\n",
    "                sample = self.__normalise_spectrogram(sample)\n",
    "                \n",
    "            X[i,] = sample\n",
    "\n",
    "            # Store label\n",
    "            y[i,] = self.__get_label((ID.split('/')[0] + ' '+ list_IDs_temp[index_2].split('/')[0] \n",
    "                                      + ' '+ list_IDs_temp[index_3].split('/')[0]) , self.max_label)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def __graph_spectrogram(self, wav_file):\n",
    "        rate, data = self.__get_wav_info(wav_file)\n",
    "        nfft = 200 # Length of each window segment\n",
    "        fs = 8000 # Sampling frequencies\n",
    "        noverlap = 120 # Overlap between windows\n",
    "        nchannels = data.ndim\n",
    "        if nchannels == 1:\n",
    "            pxx, freqs, bins, im = plt.specgram(data, nfft, fs, noverlap = noverlap)\n",
    "        elif nchannels == 2:\n",
    "            pxx, freqs, bins, im = plt.specgram(data[:,0], nfft, fs, noverlap = noverlap)\n",
    "        return pxx\n",
    "\n",
    "    # Load a wav file\n",
    "    def __get_wav_info(self, wav_file):\n",
    "        rate , data = wavfile.read(wav_file)\n",
    "        return rate, data\n",
    "\n",
    "    def __modify_spectrogram_shape(self, sample ,shape = (101,198) ):\n",
    "        a = np.zeros(shape)\n",
    "        a[: , :sample.shape[1]] = sample\n",
    "        return sample\n",
    "    \n",
    "    def __add_noise(self, sample , noise_factor):\n",
    "        noise = np.random.randn(sample.shape)\n",
    "        augmented_data = sample + noise_factor * noise\n",
    "        augmented_data = augmented_data.astype(type(sample[0]))\n",
    "        return augmented_data\n",
    "\n",
    "    def __normalise_spectrogram(self, sample):\n",
    "        mean = np.mean(sample, axis=0)\n",
    "        std = np.std(sample, axis=0)\n",
    "        sample = (sample - mean) / std\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    def __get_label(self, Y , max_label):\n",
    "        new = [] \n",
    "        for c in Y:\n",
    "            if c not in self.char_map:\n",
    "                continue\n",
    "            elif c == \"_\":\n",
    "                continue\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "                new.append(ch)\n",
    "\n",
    "        while(len(new) < max_label):\n",
    "            new.append(27)\n",
    "        label = np.array(new)\n",
    "\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f2542b77abb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_classes\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mlist_IDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_classes' is not defined"
     ]
    }
   ],
   "source": [
    "training_generator = DataGenerator(all_classes ,list_IDs, 23, char_map)\n",
    "training_generator.__getitem__(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.merge import Add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args    \n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length )    \n",
    "    \n",
    "class CTC():  \n",
    "    def __init__(self,\n",
    "                 input_size=None, \n",
    "                 output_size=None,\n",
    "                 initializer='glorot_uniform'):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.initializer = initializer\n",
    "        self.m = None\n",
    "        self.tm = None\n",
    "                   \n",
    "    def build(self, \n",
    "              conv_filters = 200,\n",
    "              conv2d_filters = 13,\n",
    "              conv_size = 5,\n",
    "              conv2d_strides = 1,\n",
    "              conv_strides = 1,\n",
    "              act = 'relu',\n",
    "              rnn_layers = 2,\n",
    "              LSTM_units = 128,\n",
    "              drop_out = 0.8):\n",
    "           \n",
    "        input_data = Input(shape = self.input_size, name = 'the_inputs')\n",
    "        x = Conv1D(conv_filters, \n",
    "                   conv_size, \n",
    "                   strides = conv_strides,\n",
    "                   padding = \"same\", \n",
    "                   name = 'conv1d1')(input_data)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(act)(x)\n",
    "        x = Conv1D(conv_filters, \n",
    "                   conv_size, \n",
    "                   strides = conv_strides,\n",
    "                   padding = \"same\", \n",
    "                   name = 'conv1d2')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(act)(x)\n",
    "        for _ in range(rnn_layers):          \n",
    "            x = Bidirectional(LSTM(LSTM_units, \n",
    "                                   return_sequences = True))(x)\n",
    "            x = Dropout(drop_out)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "        y_pred = TimeDistributed(Dense(self.output_size, \n",
    "                                       activation = 'softmax'))(x)        \n",
    "        # ctc inputs\n",
    "        labels = Input(name='the_labels', shape=[None,], dtype='int32')\n",
    "        input_length = Input(name='input_length', shape=[1], dtype='int32')\n",
    "        label_length = Input(name='label_length', shape=[1], dtype='int32')    \n",
    "        loss_out = Lambda(ctc_lambda_func, \n",
    "                          output_shape=(1,), \n",
    "                          name='ctc')([y_pred,\n",
    "                                        labels,\n",
    "                                        input_length,\n",
    "                                        label_length])        \n",
    "        self.tm = Model(inputs = input_data,\n",
    "                        outputs = y_pred)\n",
    "        self.m = Model(inputs = [input_data, \n",
    "                                 labels, \n",
    "                                 input_length, \n",
    "                                 label_length], \n",
    "                        outputs = loss_out)\n",
    "        return self.m, self.tm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc(y_true, y_pred):\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.training.Model at 0x7f50841dc3c8>,\n",
       " <keras.engine.training.Model at 0x7f50841dc400>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ctc = CTC((101,594), 28)\n",
    "model_ctc.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_inputs (InputLayer)         (None, 101, 594)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d1 (Conv1D)                (None, 101, 200)     594200      the_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 101, 200)     800         conv1d1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 101, 200)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d2 (Conv1D)                (None, 101, 200)     200200      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 101, 200)     800         conv1d2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 101, 200)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 101, 256)     336896      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 101, 256)     0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 101, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 101, 256)     394240      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 101, 256)     0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 101, 256)     1024        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 101, 28)      7196        batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           time_distributed_2[0][0]         \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,536,380\n",
      "Trainable params: 1,534,556\n",
      "Non-trainable params: 1,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ctc.m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ctc.m.compile(loss = ctc, optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c97a412299de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ctc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'training_generator' is not defined"
     ]
    }
   ],
   "source": [
    "history = model_ctc.m.fit_generator(training_generator, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xlabel(\"EPOCHS\")\n",
    "plt.ylabel(\"ACCURACY\")\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.title(\"accuray vs epochs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0693da64659c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EPOCHS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LOSS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss  vs epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"EPOCHS\")\n",
    "plt.ylabel(\"LOSS\")\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"loss  vs epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ctc.m.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
