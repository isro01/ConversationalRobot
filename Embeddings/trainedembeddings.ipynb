{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trainedembeddings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH3Zw2uUV4Zz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "6ea1f221-97ec-41ca-f968-bc3afae52cec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqzejocCX3AH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "from bs4 import BeautifulSoup\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqstjUZDYIOS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "53abfca5-3368-4eb2-83a9-cfc5ca477b66"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_GQo4jNf1dF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_1 = \"/content/gdrive/My Drive/data/data.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtvnPR1AgCl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "223f28f4-3341-4662-8e38-44c322613b5b"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopWords = set(stopwords.words('english'))\n",
        "print(stopWords)\n",
        "\n",
        "also_remove = ['  ' , '.' , '..' , '...' , '[' , ']', '}', '{', '(' , ')' ,',']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'his', 'all', 'ourselves', 'wasn', 'or', 'with', 'as', 'i', 'to', 'yourselves', 'both', 'ma', 'shouldn', \"wouldn't\", \"should've\", 'from', 'yourself', 'why', 'other', 'these', 'd', 'they', \"won't\", \"hadn't\", 'then', 'not', 'been', 'themselves', 'of', 'be', 'has', 'most', 'during', 'you', 'your', 'her', 'more', 'he', 'does', 'wouldn', 'against', 'very', 'll', 'being', 'the', 'and', 'an', \"wasn't\", 'until', 'aren', 'didn', 'because', 'how', \"mustn't\", 'hadn', 'its', 'doesn', 'once', \"isn't\", 'was', 'when', 'hasn', 'so', 'who', 'this', 'will', 'nor', \"aren't\", 'over', 'here', 't', 'o', 'weren', 'theirs', 'while', 'do', 'those', \"hasn't\", 'again', 'mustn', 'couldn', \"you'd\", 'itself', 'too', 'me', 'our', \"haven't\", 've', \"didn't\", \"couldn't\", 'that', 'is', 'into', 'any', 'y', 'by', \"shouldn't\", 'some', \"you've\", 'on', 'off', 'him', 'have', 'having', 'for', 'at', 'hers', 'through', 'after', \"weren't\", 'it', 'what', 'had', 're', 'did', 'under', 'should', 'up', 'such', 'no', 'only', 'ours', 'in', 'own', 'can', 'ain', 'mightn', 'above', 'a', 'are', 'where', 'few', 'whom', 'them', 'm', 'than', 'we', 'each', 'herself', 'there', 'now', \"don't\", \"you'll\", 'below', 'doing', 'their', 'just', 'my', 'myself', \"that'll\", \"shan't\", 'yours', 'before', \"you're\", 'were', 's', 'out', 'down', \"she's\", \"needn't\", 'which', 'needn', 'won', 'same', 'haven', 'about', 'further', 'if', 'but', 'isn', \"it's\", 'am', \"mightn't\", 'shan', 'she', 'between', 'don', \"doesn't\", 'himself'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AymMA6K5gGQm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "925eb6c0-5b3b-4f0a-f0f7-476176642e1d"
      },
      "source": [
        "reviews = []\n",
        "labels = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "with open(file_1 , 'r') as csvfile:\n",
        "  reader = csv.reader(csvfile , delimiter = ',')\n",
        "  next(reader)\n",
        "  for row in reader:\n",
        "    if row[1] == \"positive\": labels.append(1)\n",
        "    if row[1] == \"negative\" : labels.append(0)\n",
        "    # labels.append(row[1])\n",
        "    review = row[0].lower()\n",
        "    BeautifulSoup(review, \"lxml\")                                               #remove html tags\n",
        "    review = review.replace('[^\\w\\s]','')                                       #remove puntuations\n",
        "    review = review.replace(\"<br /><br />\",\" \")                                 #remove particular tags\n",
        "    review = \"\".join([i for i in review if not i.isdigit()])                    #remove_digits\n",
        "    for word in stopWords:                                                      #remove stopwords\n",
        "      stopword = \" \" + word + \" \"\n",
        "      review = review.replace(stopword , \" \")\n",
        "    for i in also_remove:\n",
        "      review = review.replace(i,\"\")\n",
        "    reviews.append(review)\n",
        "\n",
        "print(f'Time taken : {(time.time() - start_time) / 60:.2f} mins')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken : 0.72 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYOOE2kthAZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "dd0d8360-49a4-4d4c-d079-ea55a10a2bb9"
      },
      "source": [
        "print(\"review : \",reviews[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "review :  one reviewers mentioned watchingoz episode hooked right exactly happened me first thing struck oz brutality unflinching scenes violence set right word go trust me show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use word called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home manyaryans muslims gangstas latinos christians italians irish moreso scuffles death stares dodgy dealings shady agreements never far away would say main appeal show due fact goes shows dare forget pretty pictures painted mainstream audiences forget charm forget romanceoz mess around first episode ever saw struck nasty surreal say ready it watched more developed taste oz got accustomed high levels graphic violence violence injustice crooked guards who'll sold nickel inmates who'll kill order get away it well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewingthats get touch darker side\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn-pH5D8hpxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  stemming and lemmatization\n",
        "\n",
        "# from nltk.corpus import wordnet\n",
        "# from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV} # Pos tag, used Noun, Verb, Adjective and Adverb\n",
        "\n",
        "# for review in reviews:\n",
        "#   pos_tagged_text = nltk.pos_tag(review.split())\n",
        "#   review = \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_H4l_lzj1Mg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5b56ef2f-5907-42e0-da91-81531eb7ad76"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "for review in reviews:\n",
        "  length = len(review)\n",
        "  if length>max_len : max_len = length\n",
        "\n",
        "print(\"max_len :\",max_len)\n",
        "print(\"total reviews: \", len(reviews))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_len : 9452\n",
            "total reviews:  50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0toEpj3l5Kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "oov_tok = \"<OOV>\"\n",
        "vocab_size = 10000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(reviews[:3000])\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(reviews[:3000])\n",
        "padded = pad_sequences(sequences,maxlen=200, truncating=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbREDwtU_Fqq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "cc9c7f15-4b66-4c18-bcab-38893f005aea"
      },
      "source": [
        "padded = padded[:3000]\n",
        "print(padded[0])\n",
        "            "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    4 1900  790    1  337 2529  109  534\n",
            "  659  141   19   66 2530 2094 7608    1   53  428  188  109  418   54\n",
            " 1901  141   47 6739 1740    1   47 2531 5072 3889 1043  297  428 3143\n",
            "  273  244  418  330 2094    1  240 8799 3450 3290 1254    1 2324 1131\n",
            "    1  446 4708 3890 1064 4374 2994 6060  316    1    1  214 6061 7609\n",
            "  446  232    1 4375    1    1 6062 6063 2238    1    1  295 5536 6064\n",
            " 5537    1    1   38  138  147    9   50  193 1184   47  579   99  179\n",
            "  202 2413  669   85 1383 3891 2414  928  669 1468  669    1 1008   94\n",
            "   19  337   46  125 2530 1227 1780   50 1255    8  189  602 1185 1132\n",
            " 2094   89 6740  214 2325 1841  428  428 7610 6741 5073    1 2640    1\n",
            "    1    1  508  603   16  147    8   14 8800  562  558    1  638 1064\n",
            "    1  579  395  985 2027 1064  410   58 2094  101  368 2641 3643    1\n",
            "   16 1256 4709  483]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gAAivrTocvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set = []\n",
        "\n",
        "for row in range(padded.shape[0]):\n",
        "  train = []\n",
        "  for col in range(padded.shape[1]):\n",
        "    train.append(padded[row][col])\n",
        "  training_set.append(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jnJdxqX1_4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "b4eb8785-9c95-4595-a049-a06404990232"
      },
      "source": [
        "padded_train = training_set[:2000]\n",
        "padded_test = training_set[2000:3000]\n",
        "print(type(training_set))\n",
        "print(training_set[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1900, 790, 1, 337, 2529, 109, 534, 659, 141, 19, 66, 2530, 2094, 7608, 1, 53, 428, 188, 109, 418, 54, 1901, 141, 47, 6739, 1740, 1, 47, 2531, 5072, 3889, 1043, 297, 428, 3143, 273, 244, 418, 330, 2094, 1, 240, 8799, 3450, 3290, 1254, 1, 2324, 1131, 1, 446, 4708, 3890, 1064, 4374, 2994, 6060, 316, 1, 1, 214, 6061, 7609, 446, 232, 1, 4375, 1, 1, 6062, 6063, 2238, 1, 1, 295, 5536, 6064, 5537, 1, 1, 38, 138, 147, 9, 50, 193, 1184, 47, 579, 99, 179, 202, 2413, 669, 85, 1383, 3891, 2414, 928, 669, 1468, 669, 1, 1008, 94, 19, 337, 46, 125, 2530, 1227, 1780, 50, 1255, 8, 189, 602, 1185, 1132, 2094, 89, 6740, 214, 2325, 1841, 428, 428, 7610, 6741, 5073, 1, 2640, 1, 1, 1, 508, 603, 16, 147, 8, 14, 8800, 562, 558, 1, 638, 1064, 1, 579, 395, 985, 2027, 1064, 410, 58, 2094, 101, 368, 2641, 3643, 1, 16, 1256, 4709, 483]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0nb-zfAs6DO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CBOW_MODEL\n",
        "context_word = []\n",
        "target_word = []\n",
        "\n",
        "\n",
        "\n",
        "window_size = 2\n",
        "\n",
        "for sentence in padded_train:\n",
        "  for i,word in enumerate(sentence):\n",
        "    \n",
        "\n",
        "    if i- window_size >= 0 and i+ window_size < len(sentence):\n",
        "      # w = np.zeros((vocab_size+1,1))\n",
        "      # w[word] = 1\n",
        "      target_word.append(word)\n",
        "      context = []\n",
        "\n",
        "      for j in range(i-window_size ,i+window_size +1):\n",
        "        if j!= i: \n",
        "          # w = np.zeros((vocab_size+1,1))\n",
        "          # w[sentence[j]] = 1\n",
        "          context.append(sentence[j])\n",
        "\n",
        "      context_word.append(context)\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nyn2oChGhW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_context_word = []\n",
        "test_target_word = []\n",
        "\n",
        "window_size = 2\n",
        "\n",
        "for sentence in padded_test:\n",
        "  for i,word in enumerate(sentence):\n",
        "    # w = np.zeros((vocab_size+1,1))\n",
        "    # w[word] = 1\n",
        "    test_target_word.append(word)\n",
        "    test_context = []\n",
        "\n",
        "    if i- window_size >= 0 and i+ window_size < len(sentence):\n",
        "\n",
        "      for j in range(i-window_size ,i+window_size +1):\n",
        "        if j!= i: \n",
        "\n",
        "          # w = np.zeros((vocab_size+1,1))\n",
        "          # w[sentence[j]] = 1\n",
        "          test_context.append(sentence[j])\n",
        "\n",
        "      test_context_word.append(context)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRhR_Id2J8ip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3cc6216e-a087-4510-fa62-2c4c5097de92"
      },
      "source": [
        "context_word[:200]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 4],\n",
              " [0, 0, 4, 1900],\n",
              " [0, 0, 1900, 790],\n",
              " [0, 4, 790, 1],\n",
              " [4, 1900, 1, 337],\n",
              " [1900, 790, 337, 2529],\n",
              " [790, 1, 2529, 109],\n",
              " [1, 337, 109, 534],\n",
              " [337, 2529, 534, 659],\n",
              " [2529, 109, 659, 141],\n",
              " [109, 534, 141, 19],\n",
              " [534, 659, 19, 66],\n",
              " [659, 141, 66, 2530],\n",
              " [141, 19, 2530, 2094],\n",
              " [19, 66, 2094, 7608],\n",
              " [66, 2530, 7608, 1],\n",
              " [2530, 2094, 1, 53],\n",
              " [2094, 7608, 53, 428],\n",
              " [7608, 1, 428, 188],\n",
              " [1, 53, 188, 109],\n",
              " [53, 428, 109, 418],\n",
              " [428, 188, 418, 54],\n",
              " [188, 109, 54, 1901],\n",
              " [109, 418, 1901, 141],\n",
              " [418, 54, 141, 47],\n",
              " [54, 1901, 47, 6739],\n",
              " [1901, 141, 6739, 1740],\n",
              " [141, 47, 1740, 1],\n",
              " [47, 6739, 1, 47],\n",
              " [6739, 1740, 47, 2531],\n",
              " [1740, 1, 2531, 5072],\n",
              " [1, 47, 5072, 3889],\n",
              " [47, 2531, 3889, 1043],\n",
              " [2531, 5072, 1043, 297],\n",
              " [5072, 3889, 297, 428],\n",
              " [3889, 1043, 428, 3143],\n",
              " [1043, 297, 3143, 273],\n",
              " [297, 428, 273, 244],\n",
              " [428, 3143, 244, 418],\n",
              " [3143, 273, 418, 330],\n",
              " [273, 244, 330, 2094],\n",
              " [244, 418, 2094, 1],\n",
              " [418, 330, 1, 240],\n",
              " [330, 2094, 240, 8799],\n",
              " [2094, 1, 8799, 3450],\n",
              " [1, 240, 3450, 3290],\n",
              " [240, 8799, 3290, 1254],\n",
              " [8799, 3450, 1254, 1],\n",
              " [3450, 3290, 1, 2324],\n",
              " [3290, 1254, 2324, 1131],\n",
              " [1254, 1, 1131, 1],\n",
              " [1, 2324, 1, 446],\n",
              " [2324, 1131, 446, 4708],\n",
              " [1131, 1, 4708, 3890],\n",
              " [1, 446, 3890, 1064],\n",
              " [446, 4708, 1064, 4374],\n",
              " [4708, 3890, 4374, 2994],\n",
              " [3890, 1064, 2994, 6060],\n",
              " [1064, 4374, 6060, 316],\n",
              " [4374, 2994, 316, 1],\n",
              " [2994, 6060, 1, 1],\n",
              " [6060, 316, 1, 214],\n",
              " [316, 1, 214, 6061],\n",
              " [1, 1, 6061, 7609],\n",
              " [1, 214, 7609, 446],\n",
              " [214, 6061, 446, 232],\n",
              " [6061, 7609, 232, 1],\n",
              " [7609, 446, 1, 4375],\n",
              " [446, 232, 4375, 1],\n",
              " [232, 1, 1, 1],\n",
              " [1, 4375, 1, 6062],\n",
              " [4375, 1, 6062, 6063],\n",
              " [1, 1, 6063, 2238],\n",
              " [1, 6062, 2238, 1],\n",
              " [6062, 6063, 1, 1],\n",
              " [6063, 2238, 1, 295],\n",
              " [2238, 1, 295, 5536],\n",
              " [1, 1, 5536, 6064],\n",
              " [1, 295, 6064, 5537],\n",
              " [295, 5536, 5537, 1],\n",
              " [5536, 6064, 1, 1],\n",
              " [6064, 5537, 1, 38],\n",
              " [5537, 1, 38, 138],\n",
              " [1, 1, 138, 147],\n",
              " [1, 38, 147, 9],\n",
              " [38, 138, 9, 50],\n",
              " [138, 147, 50, 193],\n",
              " [147, 9, 193, 1184],\n",
              " [9, 50, 1184, 47],\n",
              " [50, 193, 47, 579],\n",
              " [193, 1184, 579, 99],\n",
              " [1184, 47, 99, 179],\n",
              " [47, 579, 179, 202],\n",
              " [579, 99, 202, 2413],\n",
              " [99, 179, 2413, 669],\n",
              " [179, 202, 669, 85],\n",
              " [202, 2413, 85, 1383],\n",
              " [2413, 669, 1383, 3891],\n",
              " [669, 85, 3891, 2414],\n",
              " [85, 1383, 2414, 928],\n",
              " [1383, 3891, 928, 669],\n",
              " [3891, 2414, 669, 1468],\n",
              " [2414, 928, 1468, 669],\n",
              " [928, 669, 669, 1],\n",
              " [669, 1468, 1, 1008],\n",
              " [1468, 669, 1008, 94],\n",
              " [669, 1, 94, 19],\n",
              " [1, 1008, 19, 337],\n",
              " [1008, 94, 337, 46],\n",
              " [94, 19, 46, 125],\n",
              " [19, 337, 125, 2530],\n",
              " [337, 46, 2530, 1227],\n",
              " [46, 125, 1227, 1780],\n",
              " [125, 2530, 1780, 50],\n",
              " [2530, 1227, 50, 1255],\n",
              " [1227, 1780, 1255, 8],\n",
              " [1780, 50, 8, 189],\n",
              " [50, 1255, 189, 602],\n",
              " [1255, 8, 602, 1185],\n",
              " [8, 189, 1185, 1132],\n",
              " [189, 602, 1132, 2094],\n",
              " [602, 1185, 2094, 89],\n",
              " [1185, 1132, 89, 6740],\n",
              " [1132, 2094, 6740, 214],\n",
              " [2094, 89, 214, 2325],\n",
              " [89, 6740, 2325, 1841],\n",
              " [6740, 214, 1841, 428],\n",
              " [214, 2325, 428, 428],\n",
              " [2325, 1841, 428, 7610],\n",
              " [1841, 428, 7610, 6741],\n",
              " [428, 428, 6741, 5073],\n",
              " [428, 7610, 5073, 1],\n",
              " [7610, 6741, 1, 2640],\n",
              " [6741, 5073, 2640, 1],\n",
              " [5073, 1, 1, 1],\n",
              " [1, 2640, 1, 1],\n",
              " [2640, 1, 1, 508],\n",
              " [1, 1, 508, 603],\n",
              " [1, 1, 603, 16],\n",
              " [1, 508, 16, 147],\n",
              " [508, 603, 147, 8],\n",
              " [603, 16, 8, 14],\n",
              " [16, 147, 14, 8800],\n",
              " [147, 8, 8800, 562],\n",
              " [8, 14, 562, 558],\n",
              " [14, 8800, 558, 1],\n",
              " [8800, 562, 1, 638],\n",
              " [562, 558, 638, 1064],\n",
              " [558, 1, 1064, 1],\n",
              " [1, 638, 1, 579],\n",
              " [638, 1064, 579, 395],\n",
              " [1064, 1, 395, 985],\n",
              " [1, 579, 985, 2027],\n",
              " [579, 395, 2027, 1064],\n",
              " [395, 985, 1064, 410],\n",
              " [985, 2027, 410, 58],\n",
              " [2027, 1064, 58, 2094],\n",
              " [1064, 410, 2094, 101],\n",
              " [410, 58, 101, 368],\n",
              " [58, 2094, 368, 2641],\n",
              " [2094, 101, 2641, 3643],\n",
              " [101, 368, 3643, 1],\n",
              " [368, 2641, 1, 16],\n",
              " [2641, 3643, 16, 1256],\n",
              " [3643, 1, 1256, 4709],\n",
              " [1, 16, 4709, 483],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0],\n",
              " [0, 0, 0, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap_6ombATq7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "6b0c059b-c839-471f-97b8-bbe734ef7e9f"
      },
      "source": [
        "target_word[:50]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 4,\n",
              " 1900,\n",
              " 790,\n",
              " 1,\n",
              " 337,\n",
              " 2529,\n",
              " 109,\n",
              " 534,\n",
              " 659,\n",
              " 141,\n",
              " 19,\n",
              " 66,\n",
              " 2530,\n",
              " 2094,\n",
              " 7608,\n",
              " 1,\n",
              " 53,\n",
              " 428]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O-YL_P3vSpm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "6b73054c-c764-47b1-fa8d-866525aaa9d3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding , Dense\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "embedding_dim = 32\n",
        "max_length = 4\n",
        "model = tf.keras.Sequential([\n",
        "         tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "         tf.keras.layers.Flatten()     \n",
        "         tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
        "         ])\n",
        "\n",
        "model.compile(loss=\"SparseCategoricalCrossentropy\",optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 4, 32)             320000    \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10000)             1290000   \n",
            "=================================================================\n",
            "Total params: 1,610,000\n",
            "Trainable params: 1,610,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA6byd3_-neu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context_word = np.array(context_word)\n",
        "target_word = np.array(target_word)\n",
        "test_context_word = np.array(test_context_word)\n",
        "test_target_word = np.array(test_target_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRWaJ-K87b9J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "ab190c86-ffaf-4a1f-a1a0-f01c6a6fae68"
      },
      "source": [
        "num_epochs = 5\n",
        "MODEL = model.fit(context_word , target_word , epochs=num_epochs, validation_data=(test_context_word, test_target_word))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "  121/12250 [..............................] - ETA: 4:14 - loss: 3.8665 - accuracy: 0.5204"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-8cd3cc1eb5b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mMODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_word\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtarget_word\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_context_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_target_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRIYBGNXCVHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9JtujY9XGSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}